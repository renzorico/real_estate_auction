{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_ids_url = \"https://subastas.boe.es/reg/subastas_ava.php?accion=Mas&id_busqueda=_ZURMUzR4WmN2Uk1VS1dkeEo1ZmFId0ppTUxjVVVQclNub3BnckVtQzdxeDJEY2Z6V2dOWVJRT0pqTlFlS01YVUUzZFdISmJpeTBEQVN1TVpnSGpodzNTYkhxNWo3ejY4eGNQVGZ1dHhCQ1hXM0lFZG1tMEhETGtBSE13ZGtiREZOSUh1d3RXMWFIZkVqNCtGbUhtWm1nd0Q4QWNYYkJrZHpqdzVDVFNOY094MFZkdkF5U2kvSXQ4Z0N4STBZakNwV0hnUnByWG5mMXRTZStidnc3YlByaEMvZXFSVkdDZXlJazF0eDlTK0hETTdMT0h4S3p6NEJJd21hdHEreXpZZVhyclFsdFI4RTRNVlBJbGlGbThicTNpT1NTWGVaNVRvRlpnMGN3Ky8xeHJHQmJDaGxBR0g3Um12V2FsbEJaZnM,-0-50\"\n",
    "\n",
    "# Fetch the HTML content\n",
    "response = requests.get(property_ids_url)\n",
    "html_content = response.text\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# Extract property IDs from the <a> elements with class 'resultado-busqueda-link-otro'\n",
    "properties_list = [a['title'] for a in soup.find_all('a', class_='resultado-busqueda-link-otro')]\n",
    "\n",
    "# Initialize an empty DataFrame to store the property info\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Loop through property IDs and extract info\n",
    "for property_id_full in properties_list:\n",
    "    # Extract the relevant part of the property ID\n",
    "    property_id = property_id_full.split(\" \")[1]\n",
    "    \n",
    "    # Construct property URL\n",
    "    property_url = f\"https://subastas.boe.es/detalleSubasta.php?idSub={property_id}\"\n",
    "    \n",
    "    # Fetch the property page\n",
    "    response = requests.get(property_url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    # Check if the property page has the expected structure\n",
    "    table_div = soup.find(\"div\", id=\"idBloqueDatos1\")\n",
    "    if table_div:\n",
    "        # Extract info from the table\n",
    "        table = table_div.find(\"table\")\n",
    "        rows = table.find_all(\"tr\")\n",
    "        \n",
    "        property_data = {}\n",
    "        for row in rows:\n",
    "            cols = row.find_all([\"th\", \"td\"])  # Including th (headers) and td (values)\n",
    "            header = cols[0].get_text(strip=True)\n",
    "            value = cols[1].get_text(strip=True) if len(cols) > 1 else \"\"  # Handle cases where there's no value cell\n",
    "            property_data[header] = value\n",
    "        \n",
    "        # Append the property info to the DataFrame\n",
    "        df = pd.concat([df, pd.DataFrame(property_data, index=[0])], ignore_index=True)\n",
    "\n",
    "# Create a list to store dictionaries of property data\n",
    "data_list = []\n",
    "\n",
    "# Iterate through each property\n",
    "for property_info in properties_list:\n",
    "    if property_info.startswith('Subasta SUB-'):\n",
    "        property_id = property_info.split(' ')[-1]\n",
    "        \n",
    "        url = f'https://subastas.boe.es/reg/detalleSubasta.php?idSub={property_id}&ver=3&idBus=_aGZaODZVK09aRlgzcFpxSzQ4SWlXa3ZOSDdnaFNaMkg1OWV0U2pHWjFwUEc2aHo5TVl3QjNtUnJUQ1FGS2ZoYmdoYS94cncxU1ZhYjNYMXFndzdyaVNvUlZpSUJHdm83eEVla3UyMElJYjJFcHpGdFB4N0RWQ20xRThPNFFrUStieGtWOWhaTlJuNGtqUXlyV3V3dFdYbWFPd3BGMnh3dlZaK2tXaElFQjVvZmhiUkdFMTJJYTYrUnRsMkU0enNHektmOUZRdnpYQmZHcERYRlY2bUdDVHE1UFZaLzJRS1BDMFlPNVhCb2R1SEYrOGljOW85djdqdE1zeWZySnNZQS8wTkhSS1lvWkxVMGJ5enJkWUhLdEhmYy9JY3g0YlF3YnpZdWo1aVhlOGs9--50&idLote=&numPagBus='\n",
    "\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        div_id_bloque_datos3 = soup.find('div', id='idBloqueDatos3')\n",
    "        if div_id_bloque_datos3:\n",
    "            data_divs = div_id_bloque_datos3.find_all('div', class_='bloque')\n",
    "            for data_div in data_divs:\n",
    "                property_data = {'Descripción': property_info, 'Property ID': property_id}\n",
    "                \n",
    "                property_table = data_div.find('table')\n",
    "                if property_table:\n",
    "                    rows = property_table.find_all('tr')\n",
    "                    for row in rows:\n",
    "                        th = row.find('th')\n",
    "                        td = row.find('td')\n",
    "                        if th and td:\n",
    "                            property_data[th.get_text(strip=True)] = td.get_text(strip=True)\n",
    "                \n",
    "                data_list.append(property_data)\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "bienes_df = pd.DataFrame(data_list)\n",
    "bienes_df.rename(columns={'Property ID':'Identificador'},inplace=True)\n",
    "columns_to_drop = ['Título jurídico', 'Información adicional', 'Valor Subasta', 'Valor de tasación','Importe del depósito', 'Puja mínima', 'Tramos entre pujas','IDUFIR']\n",
    "\n",
    "bienes_df = bienes_df.drop(columns=columns_to_drop)\n",
    "\n",
    "main_df = df.merge(bienes_df, on='Identificador', how='inner')\n",
    "main_df = main_df.dropna(subset=['Dirección', 'Código Postal'])\n",
    "main_df['Localidad'] = main_df['Localidad'].fillna('Consuela')\n",
    "main_df.fillna('No consta', inplace=True)\n",
    "columns_to_convert = ['Dirección', 'Código Postal', 'Localidad', 'Provincia']\n",
    "main_df[columns_to_convert] = main_df[columns_to_convert].apply(lambda x: x.str.upper())\n",
    "\n",
    "# Drop the 'Forma adjudicación' column\n",
    "df.drop('Forma adjudicación', axis=1, inplace=True)\n",
    "\n",
    "# Convert 'Fecha de inicio' and 'Fecha de conclusión' to datetime\n",
    "def parse_datetime(date_string):\n",
    "    return pd.to_datetime(date_string.split('CET')[0].strip(), format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "df['Fecha de inicio'] = df['Fecha de inicio'].apply(parse_datetime)\n",
    "df['Fecha de conclusión'] = df['Fecha de conclusión'].apply(parse_datetime)\n",
    "\n",
    "df['Fecha de inicio'] = df['Fecha de inicio'].dt.date\n",
    "df['Fecha de conclusión'] = df['Fecha de conclusión'].dt.date\n",
    "\n",
    "# Convert numeric columns to float with correct formatting\n",
    "numeric_columns = ['Cantidad reclamada', 'Valor subasta', 'Tasación', 'Importe del depósito']\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].apply(lambda x: x.replace(' €', '').replace('.', '').replace(',', '.') if isinstance(x, str) else x)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "special_numeric_columns = ['Puja mínima', 'Tramos entre pujas']\n",
    "\n",
    "for col in special_numeric_columns:\n",
    "    df[col] = df[col].apply(lambda x: 0 if x == 'Sin tramos' else x)\n",
    "    df[col] = df[col].apply(lambda x: x.replace(' €', '').replace('.', '').replace(',', '.') if isinstance(x, str) else x)\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "# Fill NaN values\n",
    "columns_to_fill = ['Valor subasta', 'Puja mínima', 'Cantidad reclamada', 'Tasación','Tramos entre pujas','Importe del depósito']\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)\n",
    "df['Cuenta expediente'] = df['Cuenta expediente'].fillna('0123 4567 89 0987 65')\n",
    "\n",
    "# Replace 'Sin lotes' with 0\n",
    "df['Lotes'] = df['Lotes'].replace('Sin lotes', 0)\n",
    "\n",
    "# Convert the 'Lotes' column to integer type\n",
    "df['Lotes'] = df['Lotes'].astype(int)\n",
    "\n",
    "# List of first words to filter out\n",
    "words_to_filter = [\n",
    "    'LG', 'TN', 'PEBRES', 'VIVIENDA', 'CP', 'MN', '30005', 'PD', 'AR', 'CN',\n",
    "    'GREGORIO', 'NUEVA', 'POU', 'RAMON', 'PARAJE', 'PARTIDA', 'DISEMINADO',\n",
    "    'SAN', 'PEREIJO.', 'SANTA', 'CAÑOCLAR', 'NO', 'CLOSA', 'GRAN', 'LA', 'SUERTE'\n",
    "]\n",
    "\n",
    "# Filter out rows with the specified first words in the address\n",
    "filtered_df = main_df[~main_df['Dirección'].str.split().str[0].isin(words_to_filter)]\n",
    "\n",
    "# Mapping of first words to standardized forms\n",
    "standardized_mapping = {\n",
    "    'CL': 'CALLE',\n",
    "    'LUGAR': 'LUGAR',\n",
    "    'CAMINO': 'CAMINO',\n",
    "    'CALLE': 'CALLE',\n",
    "    'AV.': 'AVENIDA',\n",
    "    'CL.': 'CALLE',\n",
    "    'C/': 'CALLE',\n",
    "    'C/COSTERETA,': 'CALLE COSTERETA',\n",
    "    'UR': 'URBANIZACION',\n",
    "    'C.': 'CALLE',\n",
    "    'CM': 'CAMINO',\n",
    "    'CR': 'CALLE',\n",
    "    'C/SANTIAGO': 'CALLE SANTIAGO',\n",
    "    'PA': 'PASAJE',\n",
    "    'CARRETERA': 'CARRETERA',\n",
    "    'AV': 'AVENIDA',\n",
    "    'PJ': 'PASAJE',\n",
    "    'C/VIRGEN': 'CALLE VIRGEN',\n",
    "    'CALLE:': 'CALLE',\n",
    "    'PARQUE': 'PARQUE',\n",
    "    'PZ': 'PLAZA',\n",
    "    'POLIGONO': 'POLIGONO',\n",
    "    'PG': 'POLIGONO',\n",
    "    'POLÍGONO': 'POLIGONO',\n",
    "    'PLAZA': 'PLAZA',\n",
    "    'C/BLASCO': 'CALLE BLASCO',\n",
    "    'PASAJE': 'PASAJE',\n",
    "    'C/CHILE': 'CALLE CHILE',\n",
    "    'C/TEIDE': 'CALLE TEIDE',\n",
    "    'C/ALFONSO': 'CALLE ALFONSO',\n",
    "    '\"EDIFICIO': 'EDIFICIO',\n",
    "    'CL/': 'CALLE',\n",
    "    'AVENIDA': 'AVENIDA',\n",
    "    'NUMERO': 'NUMERO',\n",
    "    'URB.': 'URBANIZACION',\n",
    "    'C/ANTONIO': 'CALLE ANTONIO',\n",
    "    'URB': 'URBANIZACION',\n",
    "    'RONDA': 'RONDA',\n",
    "    'RAMBLA': 'RAMBLA',\n",
    "    'URBANIZACION': 'URBANIZACION',\n",
    "    'C/LUÍS': 'CALLE LUIS',\n",
    "    'C/NICOLÁS': 'CALLE NICOLAS',\n",
    "    'PG.': 'POLIGONO',\n",
    "    'AVDA': 'AVENIDA',\n",
    "    'TRAVESIA': 'TRAVESIA',\n",
    "    'RAMAL': 'RAMAL',\n",
    "    'CTRA': 'CARRETERA',\n",
    "    'PASEO': 'PASEO',\n",
    "    'SOLAR': 'SOLAR',\n",
    "    'CAMI': 'CAMINO',\n",
    "    'C/SANTO': 'CALLE SANTO',\n",
    "    'AVD': 'AVENIDA',\n",
    "    'PARCELA': 'PARCELA',\n",
    "    'AVDA.': 'AVENIDA'\n",
    "}\n",
    "\n",
    "# Apply standardization to the 'Dirección' column\n",
    "filtered_df['Dirección'] = filtered_df['Dirección'].apply(lambda address: ' '.join([standardized_mapping.get(address.split()[0], address.split()[0].upper())] + address.split()[1:]))\n",
    "\n",
    "# Function to extract the address part until the first number\n",
    "def extract_address(address):\n",
    "    match = re.match(r'^(.*?\\d+)\\b', address)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return address\n",
    "\n",
    "# Create the \"Dirección Mapa\" column\n",
    "filtered_df['Dirección Mapa'] = filtered_df['Dirección'].apply(extract_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URL to fetch property IDs\n",
    "# # property_ids_url = \"https://subastas.boe.es/reg/subastas_ava.php?accion=Mas&id_busqueda=_Y0wyY1ppR3hqa2xCZjhyNDREcndPME1hRHdnbXJaWkV4ME9mbW5XN0RIekkyMkpHdGErVHNZYURoUjViSlJua0JMQzltMS9nVXNUMjlFa1VBbG4yT2hoSGNEUGw5WjhoaGZtQzQrSHJGVTFqS2RUODJkL0RaMUxGSEpwemhPeU5DL1o3aW1NYmVpVG93S3d6UHAzWXNXS0c3VWlsQTBuRU9zL0FjQW1jSGRnamEzTFU2aERSUzVFZDBmS0NLNjljeTZOanZNWWxjNEVoZHZhc2pwU2hKZUJGTEg1T3ViREVLTGhlRXp4MjZXZHhjWkN2YmcxQ0NXNHNxNExJVmYrSGFaSDdoRU0xL0Q2OE9VR1R2c2ZSOEE9PQ,,-0-450\"\n",
    "\n",
    "# property_ids_url = \"https://subastas.boe.es/reg/subastas_ava.php?accion=Mas&id_busqueda=_ZURMUzR4WmN2Uk1VS1dkeEo1ZmFId0ppTUxjVVVQclNub3BnckVtQzdxeDJEY2Z6V2dOWVJRT0pqTlFlS01YVUUzZFdISmJpeTBEQVN1TVpnSGpodzNTYkhxNWo3ejY4eGNQVGZ1dHhCQ1hXM0lFZG1tMEhETGtBSE13ZGtiREZOSUh1d3RXMWFIZkVqNCtGbUhtWm1nd0Q4QWNYYkJrZHpqdzVDVFNOY094MFZkdkF5U2kvSXQ4Z0N4STBZakNwV0hnUnByWG5mMXRTZStidnc3YlByaEMvZXFSVkdDZXlJazF0eDlTK0hETTdMT0h4S3p6NEJJd21hdHEreXpZZVhyclFsdFI4RTRNVlBJbGlGbThicTNpT1NTWGVaNVRvRlpnMGN3Ky8xeHJHQmJDaGxBR0g3Um12V2FsbEJaZnM,-0-50\"\n",
    "\n",
    "# # Fetch the HTML content\n",
    "# response = requests.get(property_ids_url)\n",
    "# html_content = response.text\n",
    "# # Parse the HTML using BeautifulSoup\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# # Extract property IDs from the <a> elements with class 'resultado-busqueda-link-otro'\n",
    "# properties_list = [a['title'] for a in soup.find_all('a', class_='resultado-busqueda-link-otro')]\n",
    "\n",
    "# # Initialize an empty DataFrame to store the property info\n",
    "# df = pd.DataFrame()\n",
    "\n",
    "# # Loop through property IDs and extract info\n",
    "# for property_id_full in properties_list:\n",
    "#     # Extract the relevant part of the property ID\n",
    "#     property_id = property_id_full.split(\" \")[1]\n",
    "    \n",
    "#     # Construct property URL\n",
    "#     property_url = f\"https://subastas.boe.es/detalleSubasta.php?idSub={property_id}\"\n",
    "    \n",
    "#     # Fetch the property page\n",
    "#     response = requests.get(property_url)\n",
    "#     soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "#     # Check if the property page has the expected structure\n",
    "#     table_div = soup.find(\"div\", id=\"idBloqueDatos1\")\n",
    "#     if table_div:\n",
    "#         # Extract info from the table\n",
    "#         table = table_div.find(\"table\")\n",
    "#         rows = table.find_all(\"tr\")\n",
    "        \n",
    "#         property_data = {}\n",
    "#         for row in rows:\n",
    "#             cols = row.find_all([\"th\", \"td\"])  # Including th (headers) and td (values)\n",
    "#             header = cols[0].get_text(strip=True)\n",
    "#             value = cols[1].get_text(strip=True) if len(cols) > 1 else \"\"  # Handle cases where there's no value cell\n",
    "#             property_data[header] = value\n",
    "        \n",
    "#         # Append the property info to the DataFrame\n",
    "#         df = pd.concat([df, pd.DataFrame(property_data, index=[0])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a list to store dictionaries of property data\n",
    "# data_list = []\n",
    "\n",
    "# # Iterate through each property\n",
    "# for property_info in properties_list:\n",
    "#     if property_info.startswith('Subasta SUB-'):\n",
    "#         property_id = property_info.split(' ')[-1]\n",
    "        \n",
    "#         url = f'https://subastas.boe.es/reg/detalleSubasta.php?idSub={property_id}&ver=3&idBus=_aGZaODZVK09aRlgzcFpxSzQ4SWlXa3ZOSDdnaFNaMkg1OWV0U2pHWjFwUEc2aHo5TVl3QjNtUnJUQ1FGS2ZoYmdoYS94cncxU1ZhYjNYMXFndzdyaVNvUlZpSUJHdm83eEVla3UyMElJYjJFcHpGdFB4N0RWQ20xRThPNFFrUStieGtWOWhaTlJuNGtqUXlyV3V3dFdYbWFPd3BGMnh3dlZaK2tXaElFQjVvZmhiUkdFMTJJYTYrUnRsMkU0enNHektmOUZRdnpYQmZHcERYRlY2bUdDVHE1UFZaLzJRS1BDMFlPNVhCb2R1SEYrOGljOW85djdqdE1zeWZySnNZQS8wTkhSS1lvWkxVMGJ5enJkWUhLdEhmYy9JY3g0YlF3YnpZdWo1aVhlOGs9--50&idLote=&numPagBus='\n",
    "\n",
    "#         response = requests.get(url)\n",
    "#         soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "#         div_id_bloque_datos3 = soup.find('div', id='idBloqueDatos3')\n",
    "#         if div_id_bloque_datos3:\n",
    "#             data_divs = div_id_bloque_datos3.find_all('div', class_='bloque')\n",
    "#             for data_div in data_divs:\n",
    "#                 property_data = {'Descripción': property_info, 'Property ID': property_id}\n",
    "                \n",
    "#                 property_table = data_div.find('table')\n",
    "#                 if property_table:\n",
    "#                     rows = property_table.find_all('tr')\n",
    "#                     for row in rows:\n",
    "#                         th = row.find('th')\n",
    "#                         td = row.find('td')\n",
    "#                         if th and td:\n",
    "#                             property_data[th.get_text(strip=True)] = td.get_text(strip=True)\n",
    "                \n",
    "#                 data_list.append(property_data)\n",
    "\n",
    "# # Create a DataFrame from the list of dictionaries\n",
    "# bienes_df = pd.DataFrame(data_list)\n",
    "# bienes_df.rename(columns={'Property ID':'Identificador'},inplace=True)\n",
    "# columns_to_drop = ['Título jurídico', 'Información adicional', 'Valor Subasta', 'Valor de tasación','Importe del depósito', 'Puja mínima', 'Tramos entre pujas','IDUFIR']\n",
    "\n",
    "# bienes_df = bienes_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# main_df = df.merge(bienes_df, on='Identificador', how='inner')\n",
    "# main_df = main_df.dropna(subset=['Dirección', 'Código Postal'])\n",
    "# main_df['Localidad'] = main_df['Localidad'].fillna('Consuela')\n",
    "# main_df.fillna('No consta', inplace=True)\n",
    "# columns_to_convert = ['Dirección', 'Código Postal', 'Localidad', 'Provincia']\n",
    "# main_df[columns_to_convert] = main_df[columns_to_convert].apply(lambda x: x.str.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the 'Forma adjudicación' column\n",
    "# df.drop('Forma adjudicación', axis=1, inplace=True)\n",
    "\n",
    "# # Convert 'Fecha de inicio' and 'Fecha de conclusión' to datetime\n",
    "# def parse_datetime(date_string):\n",
    "#     return pd.to_datetime(date_string.split('CET')[0].strip(), format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# df['Fecha de inicio'] = df['Fecha de inicio'].apply(parse_datetime)\n",
    "# df['Fecha de conclusión'] = df['Fecha de conclusión'].apply(parse_datetime)\n",
    "\n",
    "# df['Fecha de inicio'] = df['Fecha de inicio'].dt.date\n",
    "# df['Fecha de conclusión'] = df['Fecha de conclusión'].dt.date\n",
    "\n",
    "# # Convert numeric columns to float with correct formatting\n",
    "# numeric_columns = ['Cantidad reclamada', 'Valor subasta', 'Tasación', 'Importe del depósito']\n",
    "# for col in numeric_columns:\n",
    "#     df[col] = df[col].apply(lambda x: x.replace(' €', '').replace('.', '').replace(',', '.') if isinstance(x, str) else x)\n",
    "#     df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# special_numeric_columns = ['Puja mínima', 'Tramos entre pujas']\n",
    "\n",
    "# for col in special_numeric_columns:\n",
    "#     df[col] = df[col].apply(lambda x: 0 if x == 'Sin tramos' else x)\n",
    "#     df[col] = df[col].apply(lambda x: x.replace(' €', '').replace('.', '').replace(',', '.') if isinstance(x, str) else x)\n",
    "#     df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "# # Fill NaN values\n",
    "# columns_to_fill = ['Valor subasta', 'Puja mínima', 'Cantidad reclamada', 'Tasación','Tramos entre pujas','Importe del depósito']\n",
    "# df[columns_to_fill] = df[columns_to_fill].fillna(0)\n",
    "# df['Cuenta expediente'] = df['Cuenta expediente'].fillna('0123 4567 89 0987 65')\n",
    "\n",
    "# # Replace 'Sin lotes' with 0\n",
    "# df['Lotes'] = df['Lotes'].replace('Sin lotes', 0)\n",
    "\n",
    "# # Convert the 'Lotes' column to integer type\n",
    "# df['Lotes'] = df['Lotes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of first words to filter out\n",
    "# words_to_filter = [\n",
    "#     'LG', 'TN', 'PEBRES', 'VIVIENDA', 'CP', 'MN', '30005', 'PD', 'AR', 'CN',\n",
    "#     'GREGORIO', 'NUEVA', 'POU', 'RAMON', 'PARAJE', 'PARTIDA', 'DISEMINADO',\n",
    "#     'SAN', 'PEREIJO.', 'SANTA', 'CAÑOCLAR', 'NO', 'CLOSA', 'GRAN', 'LA', 'SUERTE'\n",
    "# ]\n",
    "\n",
    "# # Filter out rows with the specified first words in the address\n",
    "# filtered_df = main_df[~main_df['Dirección'].str.split().str[0].isin(words_to_filter)]\n",
    "\n",
    "# # Mapping of first words to standardized forms\n",
    "# standardized_mapping = {\n",
    "#     'CL': 'CALLE',\n",
    "#     'LUGAR': 'LUGAR',\n",
    "#     'CAMINO': 'CAMINO',\n",
    "#     'CALLE': 'CALLE',\n",
    "#     'AV.': 'AVENIDA',\n",
    "#     'CL.': 'CALLE',\n",
    "#     'C/': 'CALLE',\n",
    "#     'C/COSTERETA,': 'CALLE COSTERETA',\n",
    "#     'UR': 'URBANIZACION',\n",
    "#     'C.': 'CALLE',\n",
    "#     'CM': 'CAMINO',\n",
    "#     'CR': 'CALLE',\n",
    "#     'C/SANTIAGO': 'CALLE SANTIAGO',\n",
    "#     'PA': 'PASAJE',\n",
    "#     'CARRETERA': 'CARRETERA',\n",
    "#     'AV': 'AVENIDA',\n",
    "#     'PJ': 'PASAJE',\n",
    "#     'C/VIRGEN': 'CALLE VIRGEN',\n",
    "#     'CALLE:': 'CALLE',\n",
    "#     'PARQUE': 'PARQUE',\n",
    "#     'PZ': 'PLAZA',\n",
    "#     'POLIGONO': 'POLIGONO',\n",
    "#     'PG': 'POLIGONO',\n",
    "#     'POLÍGONO': 'POLIGONO',\n",
    "#     'PLAZA': 'PLAZA',\n",
    "#     'C/BLASCO': 'CALLE BLASCO',\n",
    "#     'PASAJE': 'PASAJE',\n",
    "#     'C/CHILE': 'CALLE CHILE',\n",
    "#     'C/TEIDE': 'CALLE TEIDE',\n",
    "#     'C/ALFONSO': 'CALLE ALFONSO',\n",
    "#     '\"EDIFICIO': 'EDIFICIO',\n",
    "#     'CL/': 'CALLE',\n",
    "#     'AVENIDA': 'AVENIDA',\n",
    "#     'NUMERO': 'NUMERO',\n",
    "#     'URB.': 'URBANIZACION',\n",
    "#     'C/ANTONIO': 'CALLE ANTONIO',\n",
    "#     'URB': 'URBANIZACION',\n",
    "#     'RONDA': 'RONDA',\n",
    "#     'RAMBLA': 'RAMBLA',\n",
    "#     'URBANIZACION': 'URBANIZACION',\n",
    "#     'C/LUÍS': 'CALLE LUIS',\n",
    "#     'C/NICOLÁS': 'CALLE NICOLAS',\n",
    "#     'PG.': 'POLIGONO',\n",
    "#     'AVDA': 'AVENIDA',\n",
    "#     'TRAVESIA': 'TRAVESIA',\n",
    "#     'RAMAL': 'RAMAL',\n",
    "#     'CTRA': 'CARRETERA',\n",
    "#     'PASEO': 'PASEO',\n",
    "#     'SOLAR': 'SOLAR',\n",
    "#     'CAMI': 'CAMINO',\n",
    "#     'C/SANTO': 'CALLE SANTO',\n",
    "#     'AVD': 'AVENIDA',\n",
    "#     'PARCELA': 'PARCELA',\n",
    "#     'AVDA.': 'AVENIDA'\n",
    "# }\n",
    "\n",
    "# # Apply standardization to the 'Dirección' column\n",
    "# filtered_df['Dirección'] = filtered_df['Dirección'].apply(lambda address: ' '.join([standardized_mapping.get(address.split()[0], address.split()[0].upper())] + address.split()[1:]))\n",
    "\n",
    "# # Function to extract the address part until the first number\n",
    "# def extract_address(address):\n",
    "#     match = re.match(r'^(.*?\\d+)\\b', address)\n",
    "#     if match:\n",
    "#         return match.group(1)\n",
    "#     return address\n",
    "\n",
    "# # Create the \"Dirección Mapa\" column\n",
    "# filtered_df['Dirección Mapa'] = filtered_df['Dirección'].apply(extract_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# property_bienes_url = 'https://subastas.boe.es/reg/detalleSubasta.php?idSub=SUB-AT-2023-23R3886001041&ver=3&idBus=_Y0wyY1ppR3hqa2xCZjhyNDREcndPME1hRHdnbXJaWkV4ME9mbW5XN0RIekkyMkpHdGErVHNZYURoUjViSlJua0JMQzltMS9nVXNUMjlFa1VBbG4yT2hoSGNEUGw5WjhoaGZtQzQrSHJGVTFqS2RUODJkL0RaMUxGSEpwemhPeU5DL1o3aW1NYmVpVG93S3d6UHAzWXNXS0c3VWlsQTBuRU9zL0FjQW1jSGRnamEzTFU2aERSUzVFZDBmS0NLNjljeTZOanZNWWxjNEVoZHZhc2pwU2hKZUJGTEg1T3ViREVLTGhlRXp4MjZXZHhjWkN2YmcxQ0NXNHNxNExJVmYrSGFaSDdoRU0xL0Q2OE9VR1R2c2ZSOEE9PQ,,-0-450&idLote=&numPagBus='\n",
    "\n",
    "# property_bienes_url = \"https://subastas.boe.es/reg/detalleSubasta.php?idSub=SUB-AT-2023-23R3886001041&ver=3&idBus=_aGZaODZVK09aRlgzcFpxSzQ4SWlXa3ZOSDdnaFNaMkg1OWV0U2pHWjFwUEc2aHo5TVl3QjNtUnJUQ1FGS2ZoYmdoYS94cncxU1ZhYjNYMXFndzdyaVNvUlZpSUJHdm83eEVla3UyMElJYjJFcHpGdFB4N0RWQ20xRThPNFFrUStieGtWOWhaTlJuNGtqUXlyV3V3dFdYbWFPd3BGMnh3dlZaK2tXaElFQjVvZmhiUkdFMTJJYTYrUnRsMkU0enNHektmOUZRdnpYQmZHcERYRlY2bUdDVHE1UFZaLzJRS1BDMFlPNVhCb2R1SEYrOGljOW85djdqdE1zeWZySnNZQS8wTkhSS1lvWkxVMGJ5enJkWUhLdEhmYy9JY3g0YlF3YnpZdWo1aVhlOGs9-0-50&idLote=&numPagBus=\"\n",
    "\n",
    "# # Fetch the HTML content\n",
    "# response = requests.get(property_bienes_url)\n",
    "# html_content = response.text\n",
    "\n",
    "# # Parse the HTML using BeautifulSoup\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
